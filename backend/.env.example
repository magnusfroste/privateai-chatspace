# App Configuration
APP_NAME=AI Chat App

# Admin credentials
ADMIN_EMAIL=admin@localhost
ADMIN_PASSWORD=changeme

# Security
SECRET_KEY=change-this-to-a-secure-random-string

# Default System Prompt for new workspaces (can be customized per workspace)
DEFAULT_SYSTEM_PROMPT=You are a helpful AI assistant. Answer questions accurately and provide detailed, useful responses. When given context or documents, use them to inform your answers.


# LLM (OpenAI-compatible API)
# Local vLLM: http://172.17.0.1:8000/v1
# Remote: https://api.autoversio.ai/v1
LLM_BASE_URL=http://172.17.0.1:8000/v1
LLM_API_KEY=
LLM_MODEL=default

# LLM Generation Parameters (Qwen3-80B optimized defaults)
LLM_TEMPERATURE=0.7
LLM_TEMPERATURE_TOOL=0.2
LLM_TOP_P=0.9
LLM_REPETITION_PENALTY=1.05

# Context Window Management (configured for Qwen3-80B)
MAX_CONTEXT_TOKENS=128000        # Qwen3-80B has 128K context window
CONTEXT_HISTORY_RATIO=0.7         # 70% for chat history
CONTEXT_SYSTEM_RATIO=0.15         # 15% for system prompt + RAG
CONTEXT_USER_RATIO=0.15           # 15% for user input + files

# Embedder (OpenAI-compatible API)
# Local: http://172.17.0.1:8001/v1
# Remote: https://api.autoversio.ai/v1
EMBEDDER_BASE_URL=http://172.17.0.1:8001/v1
EMBEDDER_API_KEY=
EMBEDDER_MODEL=default

# Default RAG Settings (used when creating new workspaces)
DEFAULT_TOP_N=5                      # Number of document chunks to retrieve (1-20)
DEFAULT_SIMILARITY_THRESHOLD=0.25    # Minimum similarity score (0.0-1.0)
DEFAULT_USE_HYBRID_SEARCH=true       # Use hybrid (dense + sparse) search
DEFAULT_USE_WEB_SEARCH=false         # Use external search agent
DEFAULT_CHAT_MODE=chat               # "chat" or "query"

# Vector Database (Qdrant)
QDRANT_URL=http://172.17.0.1:6333

# n8n webhook
SEARCH_AGENT_URL=https://your-n8n-webhook-url

# MCP (Model Context Protocol) Settings
# Enable MCP tool calling for intelligent web search and database access
MCP_ENABLED=false

# Firecrawl API key for fast web search (2-5 sec vs 45 sec n8n/Jina)
# Get your key at: https://www.firecrawl.dev/
FIRECRAWL_API_KEY=

# PDF to Markdown Provider
# Options: "docling-api", "marker-api", "pypdf2"
# - docling-api: External docling-serve API (GPU-accelerated, recommended, requires DOCLING_SERVICE_URL)
# - marker-api: External marker API service (GPU-accelerated, requires OCR_SERVICE_URL below)
# - pypdf2: Basic text extraction (no OCR, fallback option)
PDF_PROVIDER=docling-api

# Docling Service (GPU-accelerated docling-serve API)
# Only used when PDF_PROVIDER=docling-api
# For Easypanel: use container name, e.g., http://docling-serve:5001
# For Docker host access: http://172.17.0.1:5001
DOCLING_SERVICE_URL=http://172.17.0.1:5001

# OCR Service (Marker API for PDF to Markdown)
# Only used when PDF_PROVIDER=marker-api
# Set to Marker API URL for OCR support: http://marker-api:8001
OCR_SERVICE_URL=

# Database
DATABASE_URL=sqlite+aiosqlite:////data/app.db

# Storage
DATA_DIR=/data
DOCUMENTS_DIR=/data/documents
ORIGINALS_DIR=/data/documents/originals
MARKDOWN_DIR=/data/documents/markdown

# A/B Test Configuration (for comparing with AnythingLLM)
ABTEST_ANYTHINGLLM_URL=https://chat.autoversio.ai
ABTEST_ANYTHINGLLM_API_KEY=
ABTEST_ANYTHINGLLM_WORKSPACE=rag-test
ABTEST_PRIVATEAI_URL=http://localhost:8000
ABTEST_PRIVATEAI_API_KEY=
ABTEST_PRIVATEAI_WORKSPACE_ID=2

# Debug
DEBUG=false
